{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9969ea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers.schedules import PolynomialDecay\n",
    "from tensorflow.keras.metrics import MeanAbsoluteError\n",
    "\n",
    "wide_window = DataWindow(input_width=24, label_width=24, shift=1,label_columns=['traffic_volume'])\n",
    "\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Hiperparámetros sugeridos por Optuna\n",
    "    n_lstm_layers = trial.suggest_int(\"n_lstm_layers\", 1, 3)\n",
    "    n_units = trial.suggest_categorical(\"n_units\", [32, 64, 128, 256])\n",
    "    dropout_rate = trial.suggest_float(\"dropout\", 0.0, 0.5)\n",
    "    initial_lr = trial.suggest_float(\"initial_lr\", 1e-4, 1e-2, log=True)\n",
    "    final_lr = trial.suggest_float(\"final_lr\", 1e-6, 1e-4, log=True)\n",
    "    max_epochs = trial.suggest_int(\"max_epochs\", 20, 50)\n",
    "    patience = trial.suggest_int(\"patience\", 3, 7)\n",
    "\n",
    "    # Calcular pasos totales de entrenamiento\n",
    "    num_batches_per_epoch = sum(1 for _ in wide_window.train)\n",
    "    num_train_steps = num_batches_per_epoch * max_epochs\n",
    "\n",
    "    # Scheduler\n",
    "    lr_schedule = PolynomialDecay(\n",
    "        initial_learning_rate=initial_lr,\n",
    "        end_learning_rate=final_lr,\n",
    "        decay_steps=num_train_steps\n",
    "    )\n",
    "\n",
    "    # Modelo LSTM\n",
    "    model = Sequential()\n",
    "    for i in range(n_lstm_layers):\n",
    "        return_sequences = i < n_lstm_layers - 1\n",
    "        if i == 0:\n",
    "            model.add(LSTM(n_units, return_sequences=return_sequences))\n",
    "        else:\n",
    "            model.add(LSTM(n_units, return_sequences=return_sequences))\n",
    "        if dropout_rate > 0:\n",
    "            model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compilación con scheduler\n",
    "    model.compile(\n",
    "        loss='mse',\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "        metrics=[MeanAbsoluteError()]\n",
    "    )\n",
    "\n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=patience,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    # Entrenamiento\n",
    "    history = model.fit(\n",
    "        wide_window.train,\n",
    "        validation_data=wide_window.val,\n",
    "        epochs=max_epochs,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    return min(history.history['val_loss'])\n",
    "\n",
    "# Ejecutar la optimización\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# Mostrar mejores hiperparámetros\n",
    "print(\"Mejores hiperparámetros encontrados:\")\n",
    "print(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3cf1ba",
   "metadata": {},
   "source": [
    "usar con la clase datawindow"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
